% Chapter Template

\chapter{Basic Notions of Representation Theory} % Main chapter title

%\label{Chapter1} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}



%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------
%TODO: Add introduction/historical background 


%----------------------------------------------------------------------------------------
%	Group Actions
%
\section {Group Actions}
%----------------------------------------------------------------------------------------
\begin{defn}\label{def-grp-action}
A  \textbf{\textit{(left)} group action} of a group $G$ on a set $X$ is a map $\rho \colon G \times X \to X$ (written as $g \cdot a$, for all $g \in G$ and $a \in A$) that satisfies the following two axoims:
\begin{align}
\label{grp-action-axiom-1}&1 \cdot  x = x && \forall x \in X\\
\label{grp-action-axiom-2}&(gh) \cdot x  = g \cdot (h \cdot x) && \forall g,h \in G, x \in X
\end{align}
\end{defn}
\begin{note}
We could likewise define the concept of a \textit{right} group action, where the set elements would be multiplied by group elements on the right instead of on the left.  Throughout we shall use the term \textit{group action} to mean a \textit{left} group action.
\end{note}


\begin{prop}\label{sigma-is-a-permutation}
Let $G$ act on the set $X$.  For any fixed $g \in G$, the map $\sigma_g$ from $X$ into $X$ defined by $\sigma_g (x) = g \cdot x$ is a \textit{permutation} of the set $X$.  That is, $\sigma_g \in S_X$.
\end{prop}
\begin{proof}
We show that $\sigma_g$ is a permutation of $X$ by finding a two-sided inverse map, namely $\sigma_{g^{-1}}$. Observe that for any $x \in X$, we have
\begin{align*}
(\sigma_{g^{-1}} \circ \sigma_g) (x) &= \sigma_{g^{-1}} ( \sigma_g (x)  \\
					&= g^{-1} \cdot (g \cdot x) && \text{(by definition of $\sigma_g$ and $\sigma_{g^{-1}}$)} \\
					&= (g^{-1}g) \cdot x &&\text{(by axiom \ref{grp-action-axiom-1} of an action)} \\
					&= 1 \cdot x \\
					&= x &&\text{(by axiom \ref{grp-action-axiom-2} of an action)}.
\end{align*}
Thus $\sigma_{g^{-1}} \circ \sigma_g$ is the identity map on $X$. We can reverse the roles of $g$ and $g^{-1}$ to see that $\sigma_g \circ \sigma_{g^{-1}}$ is also the identity map on $X$.  Having a two-sided inverse, we conclude that $\sigma_g$ is a permutation of $X$.
\end{proof}

\begin{prop}\label{action-yields-hom}
Let $G$ act on the set $X$. The map from $G$ into the symmetric group $S_X$ defined by $g \mapsto \sigma_g (x) = g \cdot x$ is a group homomorphism.
\end{prop}
\begin{proof}
Define the map $\rho \colon G \to S_X$ by $\rho (g) = \sigma_g$.  We have seen from Proposition \ref{sigma-is-a-permutation} that $\sigma_g$ is indeed an element of $S_X$.  It remains to show that $\rho(g_1 g_2) = \rho(g_1) \circ \rho(g_2)$ for any $g_1, g_2 \in G$.  Observe that

\begin{align*}
\rho(g_1 g_2)(x) &= \sigma_{g_1 g_2} (x) && \text{(by definition of $\rho$)} \\
			&= (g_1 g_2) \cdot x && \text{(by definition of $\sigma_{g_1 g_2}$)} \\
			&= g_1 \cdot (g_2 \cdot x) && \text{(by axiom \ref{grp-action-axiom-1} of an action)} \\
			&= \sigma_{g_1} ( \sigma_{g_2} (x)) && \text{(by definition of $\sigma_{g_1}$ and  $\sigma{g_2}$)} \\
			&= \rho(g_1) ( \rho(g_2) (x)) && \text{(by definition of $\rho$)}\\
			&= (\rho(g_1) \circ \rho(g_2)) (x) && \text{(by definition of function composition)}.
\end{align*}
Since the values of $\rho(g_1 g_2)$ and $\rho(g_1) \circ \rho(g_2)$ agree on every element $x \in X$, these two permutations are equal. We conclude that $\rho$ is a homomorphism, since $g_1$ and $g_2$ were arbitrary elements of $G$.
\end{proof}


\begin{prop} \label{hom-yields-action}
Any homomorphism $\psi$ from the group $G$ into the symmetric group $S_X$ on a set $X$ gives rise to an action of $G$ on $X$, defined by taking $g \cdot x = \psi(g)(x)$.
\end{prop}
\begin{proof}
Suppose  that we have a homomorphism $\psi$ from $G$ into $S_X$.  We can define a map from $G \times X$ to $X$  by $g \cdot x = \psi(g)(x)$. We verify that this map satisfies the definition of a group action of $G$ on $X$:
\\ (axiom \ref{grp-action-axiom-1}) \quad $1 \cdot x = \psi(1)(x) = id_X(x) = x$
\\(axiom \ref{grp-action-axiom-2}) \quad $(gh) \cdot x = \psi(gh)(x) = (\psi(g)\psi(h))(x) = \psi(g)(\psi(h)(x)) = g \cdot (h \cdot x)$
\end{proof}

\begin{cor} \label{equivalence-of-actions}
The actions of $G$ on the set $X$ are in bijective correspondence with the homomorphisms from $G$ into the symmetric group $S_X$.
\end{cor}
\begin{proof}
By Proposition \ref{action-yields-hom}, any action of $G$ on $X$ yields a homomorphism from $G$ into $S_X$.    Conversely, any homomorphism from $G$ into $S_X$ establishes an action of $G$ on $X$ by Proposition \ref{hom-yields-action}.
\end{proof}

%Todo\colon add examples?

%----------------------------------------------------------------------------------------
%	The Definition of a Representation
%
\section{The Definition of a Representation}
%----------------------------------------------------------------------------------------
\begin{defn}
Let $G$ be a group.  A \textbf{representation} of $G$ is a homomorphism $\rho \colon  G \to GL_n (\mathbb{C})$ for some positive integer n.
\end{defn}

\begin{defn}
Two representations $\rho_1 \colon  G \to GL_n (\mathbb{C})$  and $\rho_2 \colon  G \to GL_n (\mathbb{C})$ of $G$ are \textbf{equivalent} if there exists $P \in GL_n (\mathbb{C})$ such that $\rho_2 = P^{-1} \rho_1 P$.
\end{defn}
Equivalent representations are fundamentally "the same" in some sense, but to make this precise we need to shift our thinking to linear maps instead of matrices.

\begin{defn}
\label{rep-def-1}
Let $G$ be a group, let $F$ be a field, and let $V$ be a vector space over $F$.  A \textbf{linear representation} of G is any group homomorphism $\rho\colon G \to GL(V)$. If we fix a basis for $V$, we get a representation in the previous sense.\end{defn}
 



\begin{defn}[Alternative definition] \label{rep-def-2}Let $G$ be a group, let $F$ be a field, and let $V$ be a vector space over $F$. A \textbf{linear representation} of $G$ is an action of $G$ on $V$ which preserves the linear structure of $V$, i.e. an action of $G$ on $V$ such that
\begin{align}
\label{rep-axiom-1}&g \cdot (v_1+v_2)=g \cdot v_1+g \cdot v_2 \quad && \forall g \in G, v_1, v_2 \in V \\
\label{rep-axiom-2}&g \cdot (kv) = k (g \cdot v) \quad && \forall g \in G, v \in V, k \in F
\end{align}
 \end{defn}
 
 \begin{note}
 Unless otherwise specificed, we use \textit{representation} to mean \textit{finite-dimensional complex representation}.
 \end{note}
 
 
 \begin{prop}
The definitions of a linear representation given in \ref{rep-def-1} and \ref{rep-def-2} above are equivalent.
 \end{prop}
 \begin{proof}
%\leavevmode
 \begin{itemize}
\item[$(\rightarrow)$]  Suppose that we have a homomorphism $\rho \colon G \to GL(V)$.  Note that $GL(V)$ is a subgroup of the symmetric group $S_V$ on $V$, so we can apply Proposition \ref{hom-yields-action} to obtain an action of $G$ on $V$ by $g \cdot v = \rho(g)(v)$.  We check that this action preserves the linear structure of V.
\\\ref{rep-axiom-1} \quad For any $g \in G$, $v_1, v_2 \in V$ we have $g \cdot (v_1 +  v_2) = \rho(g) (v_1 + v_2) = \rho(g)(v_1) + \rho(g)(v_2)= g \cdot v_1 + g \cdot v_2$.
\\\ref{rep-axiom-2} \quad For any $g \in G, v \in V, k \in F$ we have $g \cdot (kv) = \rho(g)(kv) = k (\rho(g)(v)) = k (g \cdot v)$.
\item[$(\leftarrow)$] Suppose that we have an action of $G$ on $V$ which preserves the linear structure of V in the sense of Definition \ref{rep-def-2}.  We can apply Proposition \ref{action-yields-hom} to obtain a homorphism $\rho \colon G \to S_V$ given by $\rho(g) = \sigma_g$ where $\sigma_g(v) = g \cdot v $.  It remains to show that the image $\rho(G)$ of $G$ under $\rho$ is actually contained in $GL(V)$, i.e. that for each $g \in G$ the map $\sigma_g$ is linear.  Fix an element $g \in G$. For any $k \in F$ and $v \in V$, we have
\begin{align*}
\sigma_g (kv) &= g \cdot (kv) && \text{(by definition of $\sigma_g$)} \\
		&= k (g \cdot v) && \text{(by property \ref{rep-axiom-1})} \\
		&= k (\sigma_g (v)) && \text{(by definition of $\sigma_g$)}.
\end{align*}
Also, for any $v_1, v_2 \in V$ we have
\begin{align*}
\sigma_g (v_1 + v_2) &= g \cdot (v_1 + v_2) && \text{(by definition of $\sigma_g$)} \\
		&= g \cdot v_1 + g \cdot v_2 && \text{(by property \ref{rep-axiom-2})} \\
		&= \sigma_g(v_1) + \sigma_g(v_2) && \text{(by definition of $\sigma_g$)}.
\end{align*}
Thus $\sigma_g$ is linear, and $\rho(G) \subset GL(V)$ proves that we  have a homomorphism $\rho \colon G \to GL(V)$.

\end{itemize}
 \end{proof}
 \begin{defn}Let $G$ be a group, let $F$ be a field, let $V$ be a vector space over $F$, and let $\rho \colon G \to GL(V)$ be a representation of $G$.  The \textbf{dimension} of the representation is the dimension of $V$ over $F$.  
 \end{defn}
% ============== Examples of Representations ===========%
 \begin{example}
 \begin{enumerate}
\item Let $V$ be a $1$-dimensional vector space over the field $F$.  The map $\rho \colon G \to GL(V)$ defined by $\rho(g) = 1$ for all $g \in G$ is a representation called the \textit{trival representation} of $G$.  The trivial representation has dimension $1$.

\item If $G$ is a finite group that acts on a finite set $X$, and $F$ is any field, then there is an associated \textit{permutation representation}  on the vector space $V$ over $F$ with basis $\{e_x \colon x \in X\}$.  We let $G$ act on the basis elements by the permutation $g \cdot e_x = e_{gx}$ for all $x \in X$ and $g \in G$. This representation has dimension $|X|$.  

\item A fundamental special case of a permutation representation that we shall return to later on is that when a finite group acts on itself by left multiplication.  In this case, the elements of $G$ form a basis for $V$, and each $g \in G$ permutes the basis elements by $g \cdot g_i = gg_i$.  This representation is called the \textit{regular representation} of $G$ and has dimension $|G|$. We shall see later that this representation encodes information about all other representations of $G$.

\item For any symmetric group $S_n$, the \textit{alternating representation} on $V=\mathbb{C}$ is given by the map $\rho \colon S_n \to GL(\mathbb{C})=\mathbb{C}^\times$ defined by $\rho(\sigma)=\text{sgn}(\sigma)$. More generally, for any group $G$ with a subgroup $H$ of index $2$, we can define an \textit{alternating representation} $\rho \colon G \to GL(\mathbb{C})$ by letting $\rho(g) = 1$ if $g \in H$ and $\rho(g) = -1$ if $g \notin H$.  (We recover our original example  by taking $G= S_n$ and $H=A_n$.)

\end{enumerate}
 \end{example}

%=========Homomorphisms===================%

\begin{defn}
A \textbf{homomorphism} between two representations $\rho_1 \colon G \to GL(V)$ and $\rho_2 \colon G \to GL(W)$ is a linear map $\psi \colon V \to W$ that interwines with (respects) the $G$-action, i.e. a map $\psi$ such that \[ \psi ( \rho_1 (g)(v)) = \rho_2(g) (\psi(v)) \quad \forall v \in V, g \in G \]  An \textbf{isomorphism} of representations is a homomorphism of representations that is also an invertible map.
\end{defn}
\begin{note}
If we have representations $(\rho_1, V)$ and $(\rho_2, W)$ and an isomorphism of vector spaces $\psi \colon V \to W$ then we can rewrite the compatibility requirement above as $\rho_2(g) = \psi \circ \rho_1(g) \circ \psi^{-1}$ for all $g \in G$.
\end{note}

Given any representation $(\rho, V)$ of a group $G$ on a vector space $V$ over a field $F$ of dimension $n$, we can fix a basis for $V$ to obtain an isomorphism of vector spaces $\psi \colon V \to F^n$.  This yields a representation $\phi$ of $G$ on $F^n$ by defining $\phi (g) = \psi \circ \rho(g) \circ \psi^{-1}$ for all $g \in G$. Clearly, this representation is isomorphic to our original representation $(\rho, V)$. In particular, this means we can always choose to view $n$-dimensional complex representations as representations on $\mathbb{C}^n$ where each $\phi(g)$ is given by an $n \times n$ matrix with entries in $\mathbb{C}$.

Suppose that we have two representations $\rho_1 \colon G \to GL_n(F)$ and $\rho_2 \colon G \to GL_m(F)$ given by $\rho_1(g) = X_g$ and $\rho_2(g) = Y_g$.  A homomorphism between these representations is then an $m \times n$ matrix $A$ such that $A X_g = Y_g A$ for all $g \in G$.   An isomorphism is given precisely when such $A$ is square and invertible.  Thus, two representations $\rho_1 \colon G \to GL_n(F)$ and $\rho_2 \colon G \to GL_n(F)$ are isomorphic if and only if there exists $A \in GL_n(F)$ such that $\rho_1(g) = A \rho_2(g) A^{-1}$ for all $g \in G$.  This establishes the following proposition:
\begin{prop} \label{iso-classes-of-reprns}
The isomorphism classes of $n$-dimensional representations of $G$ on $\mathbb{C}$ are in bijection with the quotient $Hom(G; GL_n(\mathbb{C})) / GL_n(\mathbb{C})$ of group homomorphisms $G \to GL_n(\mathbb{C})$ modulo the conjugation action of $GL_n(\mathbb{C})$.
\end{prop}



%----------------------------------------------------------------------------------------
%	Representations of Cyclic Groups
%
\section{Representations of Cyclic Groups}
%----------------------------------------------------------------------------------------
\begin{example}[Representations of $\mathbb{Z}$]
We want to classify all representations of the group $\mathbb{Z}$ under addition.  Consider an $n$-dimensional representation $\rho \colon \mathbb{Z} \to GL_n (\mathbb{C})$.  For $\rho$ to be a group homomorphism requires that $\rho(0) = \text{Id}$.  Observe that for any $0 \neq n \in \mathbb{Z}$, we have $\rho(n) = \rho( 1 + \ldots + 1) = \rho(1)^n$.  Thus $\rho$ is completely determined by the matrix $\rho(1) \in GL_n(\mathbb{C})$, and any such matrix determines a representation of $\mathbb{Z}$.  It follows that the $n$-dimensional isomorphism classes of representations of $\mathbb{Z}$ are in bijection with the conjugacy classes in $GL_n(\mathbb{C})$.  These conjugacy classes can be parameterized by the \textit{Jordan canonical form}.
\end{example}

\begin{example}[Representations of the cyclic group of order $n$]
We shall classify all representations of the cyclic group $G = \{ g, g^2, \ldots, g^{n-1}, g^n=1\}$ of order $n$. Consider a representation $\rho \colon G \to GL(V)$.  As in the previous example, we know that $\rho(1) = \text{Id}$ and $\rho(g^k) = \rho(g)^k$.  Thus our representation $\rho$ is determined completely by the linear transformation $\rho(g)$.   It will be helpful to fix a basis of $V$ so that we may view $\rho(g)$ as a matrix.  Recall from linear algebra that there exists a basis in which $\rho(g)$ takes the \textit{Jordan canonical form}

\[ \rho(g) = \begin{bmatrix}
    J_1 & 0 & \dots  &0 \\
  0 & J_2  & \dots & 0 \\
    \vdots & \vdots  & \ddots & \vdots \\
    0& 0&  \dots  & J_m
\end{bmatrix} \]
where each \textit{Jordan block} $J_k$ is of the form 
\[J_k =  \begin{bmatrix}
    \lambda & 1&0& \dots  &0 & 0 \\
     0 &\lambda& 1& \ddots & 0  & 0 \\
     0 & 0 & \lambda & \ddots& 0  & 0 \\
     0 & 0 & 0 & \ddots & 1 & 0 \\
    \vdots & \ddots & \ddots & \ddots & \ddots  & 1\\
    0& 0& 0 & \dots  & 0  &\lambda
\end{bmatrix}. \]
Now $I = \rho(g)^n$ is a block-diagonal matrix with diagonal blocks $J_k^n$, so we must have that each block $J_k^n=\text{Id}$.  Observe that we can write each block $J_k$ as $J_k = \lambda \text{Id} + N$ where $N$ is the Jordan block with $\lambda = 0$.  Thus we have 
\[ \text{Id} = J_k^n = (\lambda \text{Id} + N)^n = \lambda ^n \text{Id} + \binom{n}{1} \lambda ^{n -1} N + \binom{n}{2} \lambda ^{n-2} N^2 + \ldots + \binom {n} {n -1} \lambda N^{n -1} + N^n. \] The following lemma will show that in fact $N=0$. 
\begin{lemma}
Let $N$ be the Jordan block with $\lambda = 0$ of size $n \times n$.  For any integer $p$ with $1 \leq p \leq n - 1$, then $N^p$ is the matrix with ones in the positions $(i,j)$ where $j = i + p$ and zeroes everywhere else.  (The ones lie along a line parallel to the diagonal, $p$ steps above it.)

\begin{proof}
(By induction.)

 {\textit{Base case:}} This is simply the definition of $N$.

 \textit{Inductive step:} Suppose that the lemma holds for $N^p$.  We compute the $(i,j)$ entry of $N^{p+1}$:
\[ (N^{p+1})_{i,j} = \sum_{k=1}^{n} (N^{p})_{i,k} N_{k, j} = (N^p)_{i, i +p} N_{i +p, j} = N_{i +p, j} =\begin{cases} 
      1 & \text{if}  j = i + (p +1) \\
      0 & \text{otherwise} \\
   \end{cases}  \]

\end{proof}
\end{lemma}

Now, if $N \neq 0$ then each term $\binom {n}{k} \lambda ^ {n - k } N ^k$ for $k > 0$ would yield some non-zero non-diagonal entries (in the positions $(i,j)$ where $j= i + k$) and hence our sum could not equal the identity matrix.  We must conclude that $N = 0$, $J_k = \lambda \text{Id}$ is a $1 \times 1$ block, and $J_k ^n = \lambda ^ n \text{Id}$.  Thus $\rho(g)$ is a diagonal matrix with $n$th roots of unity as diagonal entries. 

To summarize, every $m$-dimensional representation $\rho$ of the cyclic group $G = \langle g \rangle$ of order $n$ can be seen to act (with the right choice of basis) as $m \times m$ diagonal matrices all with $n$th roots of unity along the diagonal.  In particular, these representations are determined completely by the value of $\rho(g)$ and are classified up to isomorphism by unordered $m$-tuples of $n$th roots of unity.
\end{example}

\section{Constructions from Linear Algebra}
\begin{defn} A \textbf{subrepresentation} of $V$ is a $G$-invariant subspace $W \subseteq V$; that is, a subspace $W \subseteq V$ with the property that $\rho(g) (w) \in W$ for all $g \in G$ and $w \in W$.  Note that $W$ itself is a representation of $G$ under the action $\rho(g) \restriction_W$.
\end{defn}

From elementary linear algebra, we know that given a subspace $W \subseteq V$, we can form the \textbf{quotient space} $V / W$ consisting of cosets $v + W$ in $V$.  If $W$ is a subrepresentation of $V$, we would like to define an action of $G$ on $V / W$ by the natural choice of $g (v + W) = \rho(g)(v)+ W$.  It remains to verify that this action is well defined.  If we choose another $v' \in v + W$, then $v - v' \in W$, so that $\rho(g)(v - v') \in W$ since $W$ is $G$-invariant.  Thus, the cosets $\rho(g)(v) + W$ and $\rho(g)(v') + W$ agree and this action is indeed well defined. This justifies the following definition:

\begin{defn}
Let $W$ be a $G$-subrepresentation of $V$.  Then $V/W$ forms a representation of $G$ called the \textbf{quotient representation} of $V$ under $W$ with the action $g( v + W) = \rho(g)(v) + W$.
\end{defn}

Recall also from linear algebra that given two vector spaces $V_1$ and $V_2$, we can form the \textbf{direct sum} $V_1 \oplus V_2$ consisting of ordered pairs $(v_1 ,v_2)$ where $v_1 \in V_1, v_2 \in V_2$.  

\begin{defn}
Let $V_1$ and $V_2$ be representations of $G$.  Then $V_1 \oplus V_2$ forms a representation of $G$ called the \textbf{direct sum representation} of $V_1$ and $V_2$ with the action $g (v_1, v_2) = (g \cdot  v_1, g \cdot v_2)$.
\end{defn}


\section{Complete Reducibility and Unitarity}
\begin{defn}
A representation is said to be \textbf{irreducible} if it contains no proper invariant subspaces.  It is called \textbf{completely reducible} if it decomposes into a direct sum of irreducible subrepresentations.
\end{defn}

\begin{example}

1. Any irreducible representation is, in particular, completely reducible.
2. Any $1$-dimensional representations has no proper subspaces, and is thus irreducible.
\end{example}

\begin{thm}\label{simultaneous} If $A_1, A_2, \ldots, A_r$ are linear operators on $V$ and each $A_i$ is diagonalizable, they are simultaneously diagonalizable if and only if they commute.
\end{thm}
\begin{proof}
 See Conrad \cite[Theorem 5.1] {ConradMinPoly}.
\end{proof}

\begin{thm} Every complex representation of a finite abelian group is completely reducible into irreducible representations of dimension $1$.  
\end {thm}
\begin{proof}
Take an arbitrary element $g \in G$.  Since $G$ is finite, we can find an integer $n$ such that $g^n = 1$ and $\rho(g)^n = Id$.    Hence the minimal polynomial of $\rho(g)$ divides  $x^n -1$.  Recall that $x^n-1$ has $n$ distinct roots over $\mathbb{C}$, which are generated by taking powers of $\xi = e^{\frac{2 \pi i}{n}}$.  This means that the minimal polynomial $\rho(g)$ factors into linear factors only over $\mathbb{C}$ so that $\rho(g)$ is diagonalizable.  We conclude that each $\rho(g)$ is (separately) diagonalizable since $g \in G$ was arbitrary.

Now, given any two elements $g_1, g_2 \in G$ we have 

\begin{align*}
\rho(g_1) \rho(g_2)&= \rho(g_1 g_2)&& \text{(since $\rho$ is a homomorphism)} \\
		&=  \rho(g_2 g_1) && \text{(since $G$ is abeilian)} \\
		&= \rho(g_2) \rho(g_1) && \text{(since $\rho$ is a homomorphism)}.
\end{align*}
Thus the matrices $\left\{ \rho(g)\right\}$ commute, so we may apply theorem \ref{simultaneous} to conclude that $\left\{ \rho(g)\right\}$ are simultaneously diagonalizable, say with basis $\left\{ e_1, ..., e_k \right\}$.  Then we have $V= \mathbb{C}e_1 \oplus \mathbb{C} e_2 \oplus \ldots \oplus \mathbb{C} e_n$, with each subspace $ \mathbb{C}e_1$ invariant under the action of $G$.
\end{proof}

\begin{defn}
Let $W$ be a subspace of $V$.  A \textbf{linear projection} $V$ onto $W$ is a linear map $f \colon V \to W$ such that $f \restriction_{W} = \text{Id}_W$.  If $W$ is a subrepresentation of $V$ and the map $f$ is $G$-invariant, then we say that $f$ is a $\mathbf{G}$\textbf{-linear projection}.
\end{defn}

\begin{lemma} \label{maschke-lemma}
Let $\rho \colon G \to GL(V)$ be a representation, and $W \subset V$ be a subrepresentation.  Suppose we have a $G$-linear projection 
\[ f \colon V \to W. \]
Then $\text{Ker}(f)$ is a complementary subrepresentation to $W$, i.e. $\text{Ker}(f)$ is a $G$-invariant subspace of $V$ such that
\[ V = \text{Ker}(f) \oplus W \]
\end{lemma}
\begin{proof}
First we note that $\text{Ker}(f)$ is $G$-invariant, since if $x \in \text{Ker}(f)$, then $0 = g0 = g f(x) = f(gx)$ for every $g \in G$.
Now if $y \in \text{Ker}(f) \cap W$ then $y=f(y)=0$, so $\text{Ker}(f) \cap W = 0$.  Finally $\text{Im}(f)=W$, so by the Rank-Nullity theorem
\[ \text{dim Ker}(f) + \text{dim }W = \text{dim }V. \]
Thus $V = \text{Ker}(f) \oplus W$.  
\end{proof}

\begin{thm}[Maschke's Theorem] \label{maschke}
Let $G$ be a finite group and let $F$ be a field such that $\text{char}(F) \nmid |G|$.  If $V$ is any finite-dimensional representation of $G$ over $F$, and $W \subset V$ is a subrepresentation of $V$, then there exists a complementary subrepresentation $U \subset V$, i.e. there is  a $G$-invariant subspace $U \subset V$ such that 
\[ V = W \oplus U. \]
\end{thm}
\begin{proof}
By the previous Lemma \ref{maschke-lemma} it will suffice to find a $G$-linear projection from $V$ onto $W$.  Fix a basis $\{ b_1, \ldots, b_m \}$ for $W$ and extend it to a basis  $\{ b_1, \ldots, b_m, b_{m+1}, \ldots, b_n \}$ for $V$.  Let $U = \langle b_{m+1}, \ldots, b_n \rangle$.  Then $U$ is certainly a complementary subspace to $W$, and we have a natural projection $f \colon W \oplus U \to W$ of $V$ onto $W$ with kernel $U$.  There is no reason to think that $f$ should be $G$-linear, but we can fix this by averaging over $G$.  Define $\widetilde{f} \colon V \to V$ by
\[\widetilde{f}(x) = \frac{1}{|G|} \sum_{g \in G} (\rho(g) \circ f \circ \rho(g^{-1}))(x). \]

We claim that $\widetilde{f}$ is a $G$-linear projection from $V$ onto $W$.  
First we check that $\text{Im}(f) \subset W$.  If $x \in V$ and $g \in G$, then
\[ f (\rho (g^{-1})(x)) \in W \]
and so
\[ \rho(g) ( f ( \rho( g^{-1})(x))) \in W \]
since $W$ is $G$-invariant.  Thus $\widetilde{f}(x) \in W$.  Next we check that $\widetilde{f} \restriction_{W} = \text{Id}_W$. Let $y \in W$.  For any $g \in G$, we know that $\rho(g^{-1})(y)$ is also in $W$, so
\[ f (\rho(g^{-1})(y)) = \rho (g^{-1})(y).\]
Then
\begin{align*}
\widetilde{f}(y) &=  \frac{1}{|G|} \sum_{g \in G} \rho(g) (f ( \rho(g^{-1})(y))) \\
&=\frac{1}{|G|} \sum_{g \in G} \rho(g) (\rho(g^{-1})(y)) \\
&= \frac{1}{|G|} \sum_{g \in G} \rho(g g^{-1}) (y) \\
&=\frac{1}{|G|} \sum_{g \in G} (y) \\
&= \frac{|G| y} {|G|}
\end{align*}
so indeed $\widetilde{f}$ is a linear projection of $V$ onto $W$.  Finally, we check that $\widetilde{f}$ is $G$-linear.  If $x \in V$ and $h \in G$, then
\begin{align*}
(\widetilde{f} \circ \rho(h))(x) &= \frac{1}{|G|} \sum_{g \in G} (\rho(g) \circ f \circ \rho(g^{-1}) \circ \rho(h))(x) \\
&= \frac{1}{|G|} \sum_{g \in G} (\rho(g) \circ f \circ \rho(g^{-1} h))(x) \\
&=\frac{1}{|G|} \sum_{g \in G} (\rho(hg) \circ f \circ \rho(g^{-1}))(x) \quad \text{(relabelling } g \mapsto hg \text{)} \\
&= (\rho(h) \circ \widetilde{f}) (x).
\end{align*}
\end{proof}

\begin{cor}
Let $G$ be a finite group and let $F$ be a field such that $\text{char}(F) \nmid |G|$. then any finite-dimensional representation of $G$ over $F$ is completely reducible.
\end{cor}
\begin{proof}
Let $V$ be a representation of $G$ over $F$ of dimension $n$.  If $V$ is irreducible, then $V$ is, in particular, completely reducible.  If not, then $V$ contains a proper subrepresentation $W \subset V$.  From Maschke's Theorem (\ref{maschke}), we know there exists a subrepresentation $U \subset V$ such that 
\begin{equation} \label{1.28.1} V = W \oplus U. \end{equation}
Both $W$ and $U$ have dimension less than $n$, so by induction we know that $W$ and $U$ are completely reducible. We deduce from \ref{1.28.1} that $V$ is completely reducible.
\end{proof}

\section{Vector Spaces of Linear Maps}
\begin{defn}
Let $V$ and $W$ be vector spaces.  Recall that the set $\textbf{Hom}\mathbf{(V,W)}$ of linear maps from $V$ to $W$ is itself a vector space.  If $f_1, f_2$ are two linear maps from $V$ to $W$, then we define their sum by
\begin{align*}		
(f_1 + f_2) \colon &V \to W \\		
&x \mapsto f_1(x) + f_2(x)		
\end{align*}		
and we define scalar multiplication of $\lambda \in \mathbb{C}$ by		
\begin{align*}		
(\lambda f_1) \colon &V \to W \\		
&x \mapsto \lambda f_1(x).		
\end{align*}		
%page 33 of grp 2014'%		
Now suppose we have representations $\rho_V \colon G \to GL(V)$ and $\rho_W \colon G \to GL(W)$ of $G$. Then there is a natural representation of $G$ on the vector space $\text{Hom}(V,W)$ given by
\begin{align*}		
 \rho_{\text{Hom}(V,W)}(g)  \colon \text{Hom}(V,W) &\to \text{Hom}(V,W) \\		
 f &\mapsto \rho_{W}(g) \circ f \circ \rho_{V}(g^{-1})
 \end{align*}		
for all $g \in G$. Note that $\rho_{\text{Hom}(V,W)}(g)(f)$ is certainly a linear map from $V$ to $W$ since the composition of linear maps is linear.
\end{defn}

\begin{prop} $\rho_{\text{Hom}(V,W)}$ is a representation of $G$.  That is, the map		
\begin{align*}		
  \rho_{\text{Hom}(V,W)} \colon G &\to \text{GL}(\text{Hom}(V,W)) \\		
g &\mapsto \rho_{\text{Hom}(V,W)}(g).		
\end{align*}		
 is a homomorphism.		
\end{prop}		
\begin{proof}		
We must check two things:		
\begin{enumerate}			
\item The map $g \mapsto  \rho_{\text{Hom}(V,W)}(g)$ is a homomorphism.	
\item For every $g \in G$,  $\rho_{\text{Hom}(V,W)}(g)$ is invertible.		
\end{enumerate}		
First, we check that
\begin{align*}
\rho_{\text{Hom}(V,W)}(g) \circ \rho_{\text{Hom}(V,W)}(h) \colon f &\mapsto \rho_{\text{Hom}(V,W)} (g) ( \rho_W (h) \circ f \circ \rho_V (h^ {-1})) \\
&= \rho_W (g) \circ \rho_w (h) \circ f \circ \rho_V (h^{-1} ) \circ \rho_V(g^{-1}) \\
&= \rho_W (gh) \circ f \circ \rho_V (g ^{-1} h ^{-1}) \\
&= \rho_{\text{Hom}(V,W)}(gh)(f)
\end{align*}
so indeed $\rho_{\text{Hom}(V,W)}$ is a homomorphism.  We can use this fact to see that $\rho_{\text{Hom}(V,W)}(g^{-1})$ is inverse to $\rho_{\text{Hom}(V,W)}(g)$ as
\begin{align*}
\rho_{\text{Hom}(V,W)}(g) \circ \rho_{\text{Hom}(V,W)}(g^{-1}) \ &= \rho_{\text{Hom}(V,W)} (e) \\ 
&= \text{Id}_{\text{Hom}(V,W)} \\
&= \rho_{\text{Hom}(V,W)}(g^{-1}) \circ \rho_{\text{Hom}(V,W)}(g).
\end{align*}
Thus $\rho_{\text{Hom}(V,W)}(g)$ is invertible for every $g \in G$, and $\rho_{\text{Hom}(V,W)}$ is a representation of $G$.
\end{proof}

\begin{defn}		
Let $V$ and $W$ be two representations of $G$.  The set of $G$-linear maps from $V$ to $W$ forms a subspace of $\text{Hom}(V,W)$, which we denote by $\textbf{Hom}_\mathbf{G}\mathbf{(V,W)}$.  In other words, $\text{Hom}_{G}(V,W)$ is the vector space consisting of all \textit{homomorphisms of representations} between $V$ and $W$. 
\end{defn} 

\begin{defn}
Let $\rho \colon G \to GL(V)$ be a representation.  We define the \textbf{invariant subrepresentation} $V^G \subset V$ to be the set 
\[ \{ v \in V  \mid \rho(g)(v) = v,  \quad \forall g \in G \}. \]
\end{defn}
Note that $V^G$ is a subspace of $V$, and is also clearly a subrepresentation.   It is isomorphic to a trivial representation of some dimension.

\begin{prop}\label{invariant-subrprn}
Let  $\rho_V \colon G \to GL(V)$ and $\rho_W \colon G \to GL(W)$ be representations of $G$.  Then the subrepresentation 
\[ \text{Hom}_G (V,W) \subset \text{Hom} (V,W) \]
is precisely the invariant subrepresentation $\text{Hom}(V,W) ^G$ of $\text{Hom}(V,W)$.
\end{prop}
\begin{proof}
Let $f \in \text{Hom}(V,W)$.  Then $f$ is an element of the invariant subrepresentation $\text{Hom}(V,W) ^G$ iff we have
\begin{align*}
&f = \rho_{\text{Hom}(V,W)} (g)(f)  \quad \forall g \in G \\
\iff &f = \rho_W (g) \circ f \circ \rho_V (g^{-1}) \quad \forall g \in G \\ 
\iff & f \circ \rho_V (g) = \rho_W (g) \circ f \quad \forall g \in G
\end{align*}
which is exactly the condition that $f$ is $G$-linear, i.e. that $f \in \text{Hom}_G (V,W)$.
\end{proof}

\begin{lemma}\label{invariant-subrprn-of-dir-sum}
Let $A$ and $B$ be two representations of $G$.  Then \[ (A \oplus B)^ G = A^G \oplus B^G. \]
\end{lemma}
\begin{proof}Observe that
\begin{align*}
(a,b) \in (A \oplus B)^G \iff & \rho_{A \oplus B} (g) (a,b) = (a,b) &  \forall g \in G \\
\iff & (\rho_A (g) (a), \rho_B (g) (b)) = (a,b) &  \forall g \in G \\
\iff & (a,b) \in A^G \oplus B^G.
\end{align*}
\end{proof}

\begin{lemma}\label{isomorphism-invariant-subrprns}
Let $\psi \colon A \to B$ be an isomorphism between representations of $G$. Then $\psi$ induces an isomorphism between their invariant subrepresentations 
\[ \psi \restriction_{A^G} \colon A^G \to B^G.\]
\end{lemma}
\begin{proof}
Clearly the restriction of $\psi$ to $A^G \subset A$ induces an isomorphism to some subrepresentation of $B$, but we must check that the image of this restriction actually equals $B^G$.  We verify that 
\begin{align*}
a \in A^G \iff & \rho_A (g) (a) = a & \forall g \in G \\
\iff & \psi( \rho_A (g)(a)) = \psi (a) & \forall g \in G \\
\iff & \rho_B(g) \psi(a) = \psi(a) & \forall g \in G \\
\iff & \psi(a) \in B^G.
\end{align*}
\end{proof}

\section{Schur's Lemma}
\begin{thm}\label{schur-lemma-over-c}[Schur's Lemma over $\mathbb{C}$.] If $V$ is an irreducible $G$-representation over $\mathbb{C}$, then evey linear operator $\phi \colon V \to V$ commuting with $G$ is a scalar.
\end{thm}
\begin{proof}
Let $\lambda$ be an eigenvalue of $\phi$.  Observe that the eigenspace $E_\lambda$ is $G$-invariant: If $v \in E_\lambda$, then $\phi(v) = \lambda v$.  This implies that $\phi(g v) = g \phi(v) = g (\lambda v) = \lambda (gv)$, i.e. $gv \in E_\lambda$. Since $g$ was arbitrary, $E_\lambda$ is indeed $G$-invariant.  Now $E_\lambda \neq 0$, so by irreducibility $E_\lambda = V$.  Thus $\phi = \lambda \text{Id}$.  
\end{proof}

\begin{cor}
If $V$ and $W$ are irreducible, the space $\text{Hom}_G(V,W)$ is $1$-dimensional if the representations are isomorphic, and in this case any non-zero map is an isomorphism. Otherwise,  $\text{Hom}_GG(V,W)=\{0\}$.
\end{cor}
\begin{proof}
Suppose $V$ and $W$ aren't isomorphic.  Then by Schur's Lemma, the zero map is the only $G$-linear map from $V$ to $W$, so 
\[ \text{Hom}_G (V,W) = \{0 \}. \]
On the other hand, suppose that $\phi \colon V \to W$ is an isomorphism.
Let $\psi$ be another interwining operator from $V$ to $W$.  Then $\phi ^{-1} \circ \psi \in \text{Hom}_G (V,V)$.  We can apply Schur's Lemma over $\mathbb{C}$ to see that $\phi ^{-1} \circ \psi = \lambda \text{Id}$, hence $\psi = \lambda \phi$.  So $phi$ spans $\text{Hom}_G(V,W)$.
\end{proof}

More definitions are required before we can state a more general Schur's Lemma (not restricted to just $\mathbb{C}$).

\begin{defn}
An \textbf{algebra} over a field $K$ is a ring with unit, containing a distinguished copy of $K$ that commutes with every algebra element, and with $1 \in K$ begin the algebra unit.  A \textbf{division ring} is a ring where every non-zero element is invertible, and a \textbf{division algebra} is a division ring which is also a $K$-algebra.
\end{defn}

\begin{defn}
Let $V$ be a representation of $G$ over $K$.  The \textbf{endomorphism algebra} $\text{End}^G(V)$ is the space of linear self-maps $\phi \colon V \to V$ which commute with the group action, that is, $\rho(g) \circ \phi = \phi \circ \rho(g) \quad \forall g \in G$.  The addition is the usual addition of linear maps (pointwise), and the multiplication is function composition.  The distinguished copy of $K$ is given by $K \text{Id}$.
\end{defn}

\begin{thm}\label{schur-lemma}[Schur's Lemma] If $V$ is an irreducible finite-dimensional representation of $G$ over $K$, then $\text{End}^G(V)$ is a finite-dimensional division algebra over $K$.
\end{thm}

\section{Isotypical Decomposition}

\begin{lemma}\label{lemma-uvw}
Let $U, V, W$ be three vector spaces.  Then we have natural isomorphisms
\begin{enumerate}
\item \label{lemma-uvw1} $\text{Hom} (V, U \oplus W) = \text{Hom} (V,U) \oplus \text{Hom} (V,W)$
\item \label{lemma-uvw2} $\text{Hom} (U \oplus W, V) = \text{Hom} (U,V) \oplus \text{Hom} (W,V)$.
\end{enumerate}
Additionally, if $U,V,W$ carry representations of $G$, then (\ref{lemma-uvw1}) and (\ref{lemma-uvw2}) are isomorphisms of representations.
\end{lemma}
\begin{proof}
We have inclusion and projection maps
\[
\begin{tikzcd}
U \arrow[r, hookrightarrow,  shift left,"\iota_{U}"]
& U \oplus W \arrow[r, twoheadrightarrow, shift left,"\pi_{W}"]
\arrow[l, twoheadrightarrow, shift left,"\pi_{U}"]
& W
\arrow[l, hookrightarrow, shift left, "\iota_{W}"]
\end{tikzcd}
 \]
 given by
\begin{align*}
 \iota_U &\colon x \mapsto (x , 0) \\
 \pi_U &\colon (x , y) \mapsto x
 \end{align*}
 and similarly for $\iota_W$ and $\pi_W$.  It is clear that
 \[ \text{Id}_{U \oplus W} = \iota_U \circ \pi_U + \iota_W \circ \pi_W. \]
We also note that the four spaces under consideration all have dimension $(\text{dim } V)(\text{dim } W + \text{dim } U)$.

(\ref{lemma-uvw1}) We define a map
\begin{align*}
 \psi \colon \text{Hom}(V, U \oplus W) &\to \text{Hom}(V,U) \oplus \text{Hom}(V,W) \\
 f  &\mapsto (\pi_U \circ f, \pi_W \circ f). 
\end{align*}
We claim that this map has an inverse	given by 
\begin{align*}
 \psi^{-1} \colon \text{Hom}(V,U) \oplus \text{Hom}(V,W) &\to \text{Hom}(V, U \oplus W) \\
 (f_U ,f_W) &\mapsto \iota_U \circ f_U + \iota_W \circ f_W.
\end{align*}
Check that
\begin{align*}
\psi^{-1} \circ \psi \colon f &\mapsto \iota_U \circ \pi_U \circ f + \iota_W \circ \pi_W \circ f \\
&= (\iota_U \circ \pi_U + \iota_W \circ \pi_W) \circ f\\
&= \text{Id}_{\text{Hom}(V,W)} \circ f = f.
\end{align*}
Since both vector spaces have the same dimension, $\psi \circ \psi^{-1}$ must be the identity map as well, and $\psi$ is an isomorphism of vector spaces.  Now suppose we have representations $\rho_V, \rho_W, \rho_U$ of $G$ on $V, W$ and $U$.  Then we claim $\psi$ is $G$-linear.  Recall that by definition, 
\[ \rho_{\text{Hom}(V, U \oplus W)}(g)(f) = \rho_{U \oplus W} (g) \circ f \circ \rho_V (g^{-1}).\]
Observe that for any $g \in G$ and  $f \in \text{Hom}(V, U \oplus W)$,
\begin{align*}
 \pi_U \circ ( \rho_{\text{Hom}(V, U \oplus W)}(g)(f) )&= \pi_U \circ \rho_{U \oplus W} (g) \circ f \circ \rho_V (g^{-1}) \\
 &= \rho_U (g) \circ \pi_U  \circ f \circ \rho_V (g^{-1}) \quad (\text{since } \pi_U \text{ is }G\text{-linear}) \\
 &=\rho_{\text{Hom}(U,V)}(g)(f)
 \end{align*}
 and similarly for $W$, so that 
 \begin{align*}
\psi ( \rho_{\text{Hom}(V, U \oplus W)}(g)(f)) &= (\pi_U \circ \rho_{\text{Hom}(V, U \oplus W)}(g)(f), \pi_W \circ \rho_{\text{Hom}(V,U \oplus W)}(g)(f)) \\
&=(\rho_{\text{Hom}(V,U)}(g)(\pi_U \circ f), \rho_{\text{Hom}(V,W)}(g)(\pi_W \circ f)) \\
&= \rho_{\text{Hom}(V,U) \oplus \text{Hom}(V,W)}(g)(\pi_U \circ f, \pi_W \circ f).
 \end{align*}
Thus $\psi$ is $G$-linear, and we've proved (\ref{lemma-uvw1}).

(\ref{lemma-uvw2})  Define a map
\begin{align*}
\phi \colon \text{Hom}(U \oplus W, V) &\to \text{Hom}(U,V) \oplus \text{Hom}(W,V) \\
&= (f \circ \iota_U, f \circ \iota_W).
\end{align*}
We [finish me].  The book says proof is like (1)
\end{proof}

\begin{cor}\label{invariant-subrprns-hom-spaces}
If  $U, V, W$ are representations of $G$, then there are natural isomorphisms
\begin{enumerate}
\item $\text{Hom}_G(V, U \oplus W) = \text{Hom}_G(V,U) \oplus \text{Hom}_G(V,W)$
\item $\text{Hom}_G(U \oplus W, V) = \text{Hom}_G(U, V) \oplus \text{Hom}_G(W ,V)$
\end{enumerate}
\end{cor}
\begin{proof}
(1). By Lemma (\ref{lemma-uvw}), we have an isomorphism of representations 
\[ \psi \colon \text{Hom}(V, U \oplus W) \to \text{Hom}(V, U) \oplus \text{Hom}(V,W). \]
We can apply Lemma (\ref{isomorphism-invariant-subrprns}) to obtain an isomorphism on the invariant subrepresentations
\[\text{Hom}(V, U \oplus W)^G \cong (\text{Hom}(V, U) \oplus \text{Hom}(V,W))^G.\]
Then Lemma (\ref{invariant-subrprn-of-dir-sum}) implies that 
\[\text{Hom}(V, U \oplus W)^G \cong \text{Hom}(V, U)^G \oplus \text{Hom}(V,W)^G. \]
The statement now follows from Proposition (\ref{invariant-subrprn}).

(2). The argument is similar to the one above.
\end{proof}

\begin{prop}\label{schurs-lemma-homvw}
Let $V$ and $W$ be irreducible representations of $G$.  Then
\[ \text{dim Hom}_G (V,W) =  \begin{cases} 
1 & \mbox{if $V$ and $W$ are isomorphic}  \\
0 &\mbox{if $V$ and $W$ are not isomorphic}
\end{cases} \]
\end{prop}
\begin{proof}
Suppose $V$ and $W$ are not isomorphic.  Then Schur's Lemma states that the only $G$-linear map from $V$ to $W$ is the zero map, hence $\text{Hom}_G(V,W) = \{ 0 \} $.

On the other hand, suppose that $f \colon V \to W$ is an isomorphism.  Then for any $h \in \text{Hom}_G(V,W)$, we have $f^{-1} \circ h \in \text{Hom}_G(V,V)$.  By Schur's Lemma, $f^{-1} \circ h = \lambda \text{Id}_V$ for some $\lambda \in \mathbb{C}$, i.e. $h = \lambda f$.  Thus $f$  spans $\text{Hom}_G(V,W)$.
\end{proof}

\begin{prop}\label{num-iso-subrprns}
Let $\rho \colon G \to GL(V)$ be a representation, and let \[ V = U_1 \oplus \ldots \oplus U_s \] be a decomposition of $V$ into irreducibles.  Let $W$ be any irreducible representation of $G$.  Then the number of irreducible representations in the set  $ \{ U_1, \ldots, U_s \}$ which are isomorphic to $W$ is equal to the dimension of $\text{Hom}_G(V,W)$, and also equal to the dimension of $\text{Hom}_G(W,V)$.
\end{prop}
\begin{proof}
We know from Proposition (\ref{schurs-lemma-homvw}) that the number of irreducibles representations in the set  $ \{ U_1, \ldots, U_s \}$ which are isomorphic to $W$ is equal to \[ \sum_{i=1}^s \text{dim Hom}_G(U_i,W). \]
By Corollary (\ref{invariant-subrprns-hom-spaces}), \[ \text{Hom}_G(V,W) = \bigoplus_{i=1}^s \text{Hom}_G(U_i, W) \]
so that \[  \text{dim Hom}_G(V,W) = \sum_{i=1}^s \text{dim Hom}_G(U_i, W). \]
The same argument works if we consider $\text{Hom}_G(W,V)$ and $\text{Hom}_G(W,U_i)$ in place of $\text{Hom}_G(V,W)$ and $\text{Hom}_G(U_i,W)$.
\end{proof}

\begin{thm}
Let $\rho \colon G \to GL(V)$ be a representation, and let
\begin{align*}
V = U_1 \oplus \ldots \oplus U_s \\
V = \widetilde{U_1} \oplus \ldots \oplus \widetilde{U_r}
\end{align*}
be two decompositions of $V$ into irreducible subrepresentations.  Then $s = r$, and (after reordering if necessary) $U_i$ and $\widetilde{U_i}$ are isomorphic for every $i \in \{1, \ldots, s\}$.
\end{thm}
\begin{proof}
Let $W$ be any irreducible representation of $G$.  By Proposition (\ref{num-iso-subrprns}), the number of irreducible subprepresentations in the first decomposition that are isomorphic to $W$ is equal to $\text{dim Hom}_G(V,W)$.  On the other hand, the number of irreducible subrepresentations in the second decomposition that are isomorphic to $W$ is also equal to $\text{dim Hom}_G(V,W)$.  So for any irreducible representation $W$, the two decompositions contain the same number of factors isomorphic to $W$.
\end{proof}


\section{Duals and Tensor Products}
\begin{defn}
Let $V$ be a vector space.  Recall that we define the \textbf{dual vector space} to be
\[ V^{*} = \text{Hom}(V,\mathbb{C}).\]
This is a special case of $\text{Hom}(V,W)$ where $W = \mathbb{C}$. We know that if $\{ b_1, \ldots, b_n \} $ is a basis for $V$, then there is a \textbf{dual basis} $\{ f_1, \ldots, f_n \}$ for $V$ defined by
\[ f_i (b_j) = \begin{cases} 1 &\text{if } i=j \\ 0 &\text{if } i \neq j.  \end{cases} \]
Let $\rho_V \colon G \to GL(V)$ be a representation of $G$, and let $\mathbb{C}$ be the $1$-dimensional trival representation of $G$.  Then we have seen that $V^{*}$ carries a representation of $G$ defined by
\[ \rho_{\text{Hom}(V,\mathbb{C})} (g) (f) = f \circ \rho_V ( g^{-1}) \]
We call this the \textbf{dual representation} to $\rho_V$ and denote it by $\rho_V^{*}$.
\end{defn}
\begin{prop}\label{matrix-of-dual}
If we fix a basis for $V$, then $\rho_{V^*}(g)$ is given by the matrix 
\[( \rho_V (g^{-1}) )^T \]
with respect to the dual basis.
\end{prop}
\begin{proof}
Fix a basis $\{ a_1, \ldots, a_n \}$ for $V$.  Let $\rho_V (g^{-1})$ be described by the matrix $M$, so that 
\[ \rho_V (g^{-1} ) (a_j) = \sum_{1 \leq i \leq n} M_{ij} a_i. \]
Let $\rho_V^* (g)$ be described by the matrix $N$ with respect to the dual basis $\{ \alpha_1, \ldots, \alpha_n \}$, so that
\[ \rho_V^* (g) (\alpha_j)  = \sum_{1 \leq i \leq n} N_{ij} \alpha_i. \]
Then
\begin{align*}
N_{ji} &= \sum_{1 \leq k \leq n} N_{ki} \delta_{kj} \\
	&=\sum_{1 \leq k \leq n} N_{ki}( \alpha_k a_j )\\
	&= \left( \sum_{1 \leq k \leq n} N_{ki} \alpha_k \right) a_j \\
	&= (\rho_V^* (g) (\alpha_i )) (a_j) \\
	&= (\alpha_i \circ \rho_V (g^{-1}) ) (a_j) \quad \text{(by definition of the dual representation)} \\
	&= \alpha_i ( \rho_V(g^{-1}) (a_j)) \\
	&= \alpha_i \left(  \sum_{1 \leq k \leq n} M_{kj} a_k \right) \\
	&= \sum_{1 \leq k \leq n} M_{kj} \alpha_i a_k \\
	&= \sum_{1 \leq k \leq n} M_{kj} \delta_{ik} \\
	&= M_{ij}.
\end{align*}
That is,  $N=M^T$.
\end{proof}

\begin{defn}
Suppose $V$ and $W$ are two vector spaces over a field $K$. Then we define a new vector space called the \textbf{tensor product} of $V$ and $W$, denoted by $V \otimes_{K} W$.  This space is the quotient of the free vector space on $V \times W$ (with basis given by formal symbols $v \otimes w, v\in V, w \in W$), by the subspace $D$ spanned by all elements of the form
\begin{align*}
(v_1 + v_2, w) - (v_1 , w) - (v_2 , w) \\
(v , w_1 + w_2) - (v , w_1) - (v , w_2) \\
(k \cdot v , w) -( v , k \cdot w)
\end{align*}
for $v, v_1, v_2 \in V, w, w_1, w_2 \in W$, and $k \in K$. When the ground field $K$ is clear it can be omitted from the notation.  The elements of $V \otimes W$ are called \textbf{tensors}, and the coset $v \otimes w$ of $(v,w)$ in $V \otimes W$ is called a \textbf{simple tensor}.  We have the relations
\begin{align*}
(v_1 + v_2) \otimes w &= v_1 \otimes w + v_2 \otimes w \\
v \otimes (w_1 + w_2) &= v \otimes w_1 + v \otimes w_2 \\
(k \cdot v) \otimes w &= v \otimes (k \cdot w) = k \cdot (v \otimes w).
\end{align*}
\end{defn}

\begin{defn}
Let $V$ and $W$ be vector spaces over $K$.  A map $\phi \colon V \times W \to K$ is called $\mathbf{K}$\textbf{-balanced} if \begin{align*}
\phi( v_1 + v_2, w) &= \phi(v_1, w) + \phi(v_2, w) \\
\phi(v, w_1 + w_2) &= \phi (v, w_1) + \phi(v, w_2) \\
\phi(v, kw) &= \phi( kv, w)
\end{align*}
for all $v \in V, w \in W, k \in K$.
\end{defn}
\begin{example}
Mapping $V \times W$ to the free $K$-vector space on $V \times W$, and then passing to the quotient defines a map $\iota \colon V \times W \to V \otimes W$ with $\iota (v,w) = v \otimes w$.  From the relations satisfied by the tensor product, we see that the map $\iota$ is $K$-balanced.
\end{example}

%see pf. 364 of dummit-foote
\begin{thm}\label{universal-prop-tensor}[Universal property of the tensor product]  Suppose $V,W$, and $U$ are vector spaces over the field $K$.  Let $\varphi \colon V \times W \to U$ be a $K$-balanced map, and let $\iota$ be the map above.  Then there is a unique linear map $\varphi \colon V \otimes W \to U$ such that $\varphi$ factors through $\iota$, i.e., $\varphi = \varphi \circ \iota$.
\end{thm}
\begin{proof}
The map $\varphi$ extends by linearity to a linear transformation $\widetilde{\varphi}$ from the free vector space on $V \times W$ to $U$ such that $\widetilde{\varphi}(v , w) = \varphi (v,w)$ for all $v \in V, w \in W$.  Since $\varphi$ is $K$-balanced, $\widetilde{\varphi}$ maps each of the elements which span the subspace $D$ from the definition of the tensor product to 0.  For example,
\[ \widetilde{\varphi} ((kv, w) - (v, kw)) = \varphi(kv, w ) - \varphi (v, kw) = 0. \]
Thus the kernel of $\widetilde{\varphi}$ contains $D$, and so $\widetilde{\varphi}$ induces a linear map $\varphi \colon V \otimes W \to U$.  Then
\[ \varphi( v \otimes w) = \widetilde{\varphi}( v , w) = \varphi ( v , w) \]
i.e., $\varphi = \varphi \circ \iota$. Note that $\varphi$ is completely determined by this equation since the elements $v \otimes w$ span $V \otimes W$.
\end{proof}



\begin{prop}
Let $\{ e_i \}_{i \in I}$ and $\{ f_j \}_{j \in J}$ be bases for $V$ and $W$.  Then $\{ e_i \otimes f_j | i \in I, j \in J\}$  is a basis for $V \otimes W$.
\end{prop}
\begin{proof}
An elementary tensor in $V \otimes W$ has the form $v \otimes w$.  Write $v = \sum_i a_i e_i$ and $w = \sum_j b_j f_j$, where all but finitely many of $a_i$ and $b_j$ are 0.  Then 
\[ m \otimes n = \sum_i a_i e_i \otimes \sum_j b_j f_j  = \sum_{i,j} a_i b_j e_i \otimes f_j\]
is a linear combination of the tensors $e_i \otimes f_j$.  Since every tensor can be written as a sum of elementary tensors, the elements $e_i \otimes f_j$ span $V \otimes W$.

Now, we must show that this spanning set is linearly independent.  Suppose that $\sum_{i,j} c_{ij} e_i \otimes f_j = 0$, where all but finitely many $c_{ij}$ are 0.  We want to show that $c_{ij} = 0$ for every $i \in I, j \in J$. Fix two elements $ i_0 \in I$ and $j_0 \in J$.  To show that $c_{i_0 j_0} = 0$, consider the $K$-balanced map
\begin{align*}
V \times W &\to K \\
(v,w) &\mapsto a_{i_0} b_{j_0}
\end{align*}
 where $v = \sum_i a_i e_i$ and $w = \sum_j b_j f_j$. By the universal property of tensor products, there is a linear map $f_0 \colon V \otimes W \to K$ such that $f_0 (v \otimes w) = a_{i_0} b_{j_0}$ on any elementary tensor $v \otimes w$.  In particular, $f_0 (e_{i_0} \otimes f_{j_0}) = 1$ and  $f_0 (e_{i} \otimes f_{j}) = 0$ for $(i,j) \neq (i_0, j_0)$.  Applying $f_0$ to our assumption that $\sum_{i,j} c_{ij} e_i \otimes f_j = 0$ in $V \otimes W$ tells us that $c_{i_0 j_0} =0$ in $K$.  
\end{proof}

\begin{prop}
There are natural isomorphisms 
\begin{enumerate}
\item $(U \otimes V) \otimes W \cong U \otimes (V \otimes W)$ 
\item $( U \oplus V) \otimes W \cong (U \otimes W) \oplus (V \otimes W)$.
\end{enumerate}
\end{prop}
\begin{proof}
(1.) For each fixed $w \in W$, the mapping $(u,v) \mapsto u \otimes ( v \otimes w)$ is $K$-balanced, so by Theorem \ref{universal-prop-tensor} there is a unique linear map from $U \otimes V$ to $U \otimes ( V \otimes W)$ with $u \otimes v \mapsto u \otimes (v \otimes w)$.  This shows that the map from $(U \otimes V ) \times W$ to $U \otimes ( V \otimes W)$ given by $(u \otimes v, w ) \mapsto u \otimes (v \otimes w)$ is well defined.  This map is also $K$-balanced, and  thus another application of Theorem \ref{universal-prop-tensor} shows that it induces a linear map $(U \otimes V) \otimes W \to U \otimes ( V \otimes W)$ such that $(u \otimes v) \otimes w \mapsto u \otimes (v \otimes w)$.  In a similar manner, we can construct a map $U \otimes (V \otimes W) \to (U \otimes V) \otimes W$ with $u \otimes ( v \otimes w) \mapsto (u \otimes v) \otimes w$ which is inverse to our first map.  This proves the isomorphism.

(2.)  The map $(U \oplus V ) \times W \to (U \oplus W) \otimes (V \oplus W)$ defined by $((u, v ) , w) \mapsto (u \otimes w, v \otimes w)$ is clearly $K$-balanced.  Thus it induces a linear map $f \colon (U \oplus V) \otimes W \to (U \otimes W) \oplus (V \otimes W)$ with 
\[ f ( ( u, v ) \otimes w) = (u \otimes w, v \otimes w). \]
In the other direction, we use the $K$-balanced maps $U \times W \to (U \oplus V) \otimes W$ and $V \times W \to (U \oplus V) \otimes W)$ given by $(u, w) \mapsto (u, 0)\otimes w$ and $(v,w) \mapsto (0,v) \otimes w$ to obtain linear maps from $U \otimes W$ and $V \otimes W$ to $(U \oplus V) \otimes W$.  Together these maps give a linear transformation $g$ from the direct sum $(U \otimes W) \oplus ( V \otimes W)$ to $(U \oplus V) \otimes W)$ with 
\[ g ( u \otimes w_1, v \otimes w_2) = (u, 0) \otimes w_1 + (0,v) \otimes w_2. \]
It is straightforward to see that $f$ and $g$ are inverse linear transformations, and the isomorphism holds.
\end{proof}


Now let $V$ and $W$ be two representations of $G$.
\begin{defn}
We can define a representation of $G$ on $V \otimes W$ called the \textbf{tensor product representation}. We let
\[ \rho_{V \otimes W} (g) \colon V \otimes W \to V \otimes W \]
be the linear map given by
\[ \rho_{V \otimes W} (g) \colon a_i \otimes b_j \mapsto \rho_V (g) (a_i) \otimes \rho_W (g) (b_j).\]
\end{defn}
Suppose $\rho_V (g)$ is described by the matrix $M$ and 
$\rho_W (g)$ is described by the matrix $N$ in the given bases $\{ a_1, \ldots, a_n\}$ for $V$  and $\{b_1, \ldots, b_m \}$ for W.  Then
\begin{align*}
\rho_{V \otimes W} (g) \colon a_i \otimes b_t &\mapsto \left( \sum_{j=1}^n M_{ji} a_j \right) \otimes \left( \sum_{s=1}^m N_{st} b_s \right) \\
&= \sum_{\substack{j \in [1,n] \\  s \in [1,m]}} M_{ji} N_{st} a_j \otimes b_s.
\end{align*}
So $\rho_{V \otimes W}$ is described by the $nm \times nm$ matrix $M \otimes N$ whose entries are 
\[ [ M \otimes N ]_{js, it} = M_{ji} N_{st}. \]
This matrix has $nm$ rows, and to specify a row we need a pair of numbers $(j, s)$ where $j \in \{ 1, \ldots, n \}$ and $s \in \{ 1, \ldots, m \}$.  

\begin{prop}
Let $V$ and $W$ be representations of $G$.  Then $V \otimes W$ is isomorphic to $\text{Hom}(V^{*},W)$.
\end{prop}
\begin{proof}
Let $\{ a_1,  \ldots, a_n\}$ be a basis for $V$, let $\{\alpha_1, \ldots, \alpha_n \}$ be the corresponding dual basis for $V^{*}$, and let $\{b_1,  \ldots,b_m\}$ be a basis for $W$.  Then $\text{Hom}(V^*,W)$ has a basis $\{ f_{it} | 1 \leq i \leq n, 1 \leq t \leq m \}$ where
\begin{align*}
f_{it} (\alpha_j) = \begin{cases} b_t &\text{if } j = i\\ 0 &\text{if } j \neq i \end{cases}
\end{align*}
We obtain an isomorphism of vector spaces between $\text{Hom}(V^*,W)$ and $V \otimes W$ by the map
\[ \psi (f_{it}) = a_i \otimes b_t \]
extended to all of  $\text{Hom}(V^*,W)$ by linearity.  It remains to show that this isomorphism of vector spaces yields an isomorphism of representations, i.e. we need to check that 
\[ \psi \circ \rho_{\text{Hom}(V^*,W)} (g) = \rho_{V \otimes W} (g) \circ \psi \]
for all $g \in G$.  Fix $g \in G$, and let $M$ and $N$ denote the matrices which describe $\rho_V (g)$ and $\rho_W (g)$ in the given bases.  
By definition,
\[ \rho_{\text{Hom}(V^{*},W)} (g) (f_{it}) = \rho_W (g) \circ f_{it} \circ \rho_{V^{*}}(g^{-1}). \]
Now $\rho_{V^{*}} (g^ {-1})$ is given by the matrix $M^T$ in the dual basis by Proposition \ref{matrix-of-dual}, so
\[\rho_{V^{*}} (g^ {-1}) ( \alpha_k )= \sum_{j=1}^n M_{kj} \alpha_{j}. \]
Then
\[ f_{it} \circ \rho_{V^{*}} (g^ {-1}) (\alpha_k) = M_{ki} b_t \]
which means that 
\[ \rho_W (g) \circ f_{it} \circ \rho_{V^{*}} (g^ {-1}) ( \alpha_k) = M_{ki} \left( \sum_{s=1}^m N_{st} b_s \right). \]
Thus, if we write $\rho_W (g) \circ f_{it} \circ \rho_{V^{*}} (g^ {-1})$ in terms of the basis $\{ f_{js} \}$, we have 
\[\rho_W (g) \circ f_{it} \circ \rho_{V^{*}} (g^ {-1}) = \sum_{\substack{j \in [1,n] \\  s \in [1,m]}} M_{ji} N_{st} f_{js} \]
(since both sides agree on every basis vector $\alpha_k$).  Therefore,
\begin{align*}
\psi \circ \rho_{\text{Hom}(V^*,W)} (g) (f_{it}) &= \psi \left(\rho_W (g) \circ f_{it} \circ \rho_{V^{*}} (g^ {-1}) \right) \\
&= \psi \left(\sum_{\substack{j \in [1,n] \\  s \in [1,m]}} M_{ji} N_{st} f_{js} \right) \\
&=  \sum_{\substack{j \in [1,n] \\  s \in [1,m]}} M_{ji} N_{st} a_j \otimes b_s \\
&= \rho_{V \otimes W} (g) (a_i \otimes b_t) \quad \text{(by definition of the tensor product representation)} \\
&= \rho_{V \otimes W} (g) \circ \psi (f_{it})
\end{align*}
\end{proof}


\section{Character Theory}
\begin{defn}
The \textbf{character} of a representation $\rho \colon G \to GL(V)$ is the function $\chi_V \colon G \to \mathbb{C}$ defined by $\chi_V(g) = \text{Tr}(\rho(g))$.
\end{defn}
\begin{note}
The character is of a representation is not a homorphism in general, since $\text{Tr}(MN) \neq \text{Tr}(M) \text{Tr}(N)$ in general.
\end{note}

\begin{prop}\label{basic-props-of-char} (Basic Properties)
\begin{enumerate}
\item $\chi_V$ is conjugation invariant: $\chi_V (h g h^{-1}) = \chi_V (g)$ for all $g , h \in G$.
\item $\chi_V (1) = \text{\emph{dim }} V$.
\item \label{char-of-inverse} $\chi_V (g^{-1}) = \overline{\chi_V (g)}$ for all $g \in G$.
\item $\chi_{V^*} (g) =  \overline{\chi_V (g)}$ for all $g \in G$.
\end{enumerate}
\end{prop}

\begin{proof}
\begin{enumerate}
\item $\chi_V (h g h^{-1} = \text{Tr}(h g h^{-1}) = \text{Tr}(g h h^{-1}) = \text{Tr} (g) = \chi_V(g)$ for any $g,h \in G$.
\item $\chi_V(1) = \text{Tr}(\text{Id} _V) = \text{dim } V$.
\item Since $G$ is finite, we have seen that $\rho(g)$ is a diagonal matrix with roots of unity along the diagonal with the right choice of basis.  The inverse of a root of unity is given by its complex conjugate, so under this same basis, $\rho(g)^{-1}$ is clearly given by $\overline{\rho(g)}$.  Thus, $\chi_V(g^{-1}) = \text{Tr}(\rho(g^{-1})) = \text{Tr}(\rho(g)^{-1}) = \text{Tr}(\overline{\rho(g)}) = \overline{ \text{Tr} (\rho(g))} = \overline {\chi_V(g)}$.
\item \begin{align*}
 \chi_{V^*}(g) &= \text{Tr}(\rho_{V^*}(g)) \\
 &= \text{Tr}(\rho_V (g^{-1})^T) \quad \text{ (by Proposition \ref{matrix-of-dual})} \\
 &= \text{Tr}(\rho_V(g^{-1})) \\
 &= \overline{\chi_V (g)}  \quad \text{ (by \ref{char-of-inverse})}
\end{align*}
\end{enumerate}
\end{proof}

\begin{prop}\label{iso-reprns-same-char}
Isomorphic representations have the same character.
\end{prop}
\begin{proof}
We have seen in Proposition \ref{iso-classes-of-reprns} that isomorphic representations can be described by the same set of matrices with the right choice of bases.  Thus they have the same trace.
\end{proof}
We will see later that the converse is true - if two representations have the same character, then they are isomorphic.

\begin{prop}
Let $\rho_V \colon G \to GL(V)$ and $\rho_W \colon G \to GL(W)$ be representations of $G$ with characters $\chi_V$ and $\chi_W$.
\begin{enumerate}
\item $\chi _{V \oplus W} = \chi_V + \chi_W$.
\item $\chi_{V \otimes W} = \chi_V \cdot \chi_W$.
\end{enumerate}
\end{prop}
\begin{proof}
\begin{enumerate}
Pick bases for $V$ and $W$, so that $\rho_V (g)$ and $\rho_W (g)$ are described by matrices $M$ and $N$.  
\item $\rho_{V \oplus W} (g)$ is described by the block-diagonal matrix
\[ \begin{bmatrix}
M & 0 \\
0 & N \\
\end{bmatrix} \]

So we have $\text{Tr} (\rho_{V \oplus W} (g)) = \text{Tr} (M) + \text{Tr}(N) = \text{Tr}(\rho_V (g)) + \text{Tr} (\rho_W (g))$.
\item $\rho_ {V \otimes W}(g)$ is given by the matrix
\[ [M \otimes N ]_{js, it} = M_{ji} N_{st} \]
so
\begin{align*}
\text{Tr} (M \otimes N) &= \sum_{i,t} [M \otimes N]_{js,it} \\
	&= \sum_{i,t} (M_{ii} N_{tt}) \\
	&= \text{Tr} (M) \text{Tr} (N).
\end{align*}
Thus $\chi_{V \otimes W} (g)= \chi_V (g) \chi_W(g)$.
\end{enumerate}
\end{proof}

\begin{prop}
\begin{enumerate}
\item Let $\{ V_i \}$ be the irreducible representations of $G$, with $d_i$  the dimension of  $V_i$ and $\chi_i$ the corresponding irreducible character.  Then
\[ \chi_{\text{reg}} = d_1 \chi_1 + \ldots + d_r \chi_r \]

\item \[  
\chi_{\text{reg}} (g) = \begin{cases} 
|G| &\text{if } g = e \\ 
0 & \text{if } g \neq e 
\end{cases}  \]
\end{enumerate}
\end{prop}

\begin{defn}
Let $\mathbb{C}^G$ denote the set of all functions from $G$ to $\mathbb{C}$.  Then $\mathbb{C}^G$ is a vector space with the sum of two functions defined pointwise and with scalar multiplication defined for $f \in \mathbb{C}^G, \lambda \in \mathbb{C}$ by 
\begin{align*}
\lambda f \colon G &\to \mathbb{C} \\
g &\mapsto \lambda f(g).
\end{align*}
A basis for $\mathbb{C}^G$ is clearly given by the set of functions 
\[\{ \delta_g | g \in G  \} \]
defined by 
\[ \delta_g \colon h \mapsto \begin{cases}  1 &\text{if } h = g \\
 0 &\text{if } h \neq g
\end{cases} \]
\end{defn}

\begin{defn}
Let $\varphi, \psi \in \mathbb{C}^G$.  We define an \textbf{inner product}  on $\mathbb{C}^G$ by 
\[ \langle \varphi | \psi \rangle = \frac{1}{|G|} \sum_{g \in G} \varphi(g) \overline{\psi(g)}.\]
\end{defn}
It is easy to see that $\langle \varphi | \psi \rangle$ is linear in the first variable, conjugate-linear in the second variable (i.e., $\langle \varphi | \lambda \psi \rangle = \overline{\lambda}	\langle \varphi | \psi \rangle$) , and that $\langle \varphi | \psi \rangle = \overline {\langle \psi | \varphi \rangle}$.  These three properties are the definition of a Hermitian inner product.  Note that our basis elements $\delta_g$ are orthogonal with respect to this inner product, but not orthonormal since 
\[ \langle \delta_g | \delta_g \rangle = \begin{cases} \frac{1}{|G|} &\mbox{if } h = g \\ 0 &\mbox{if } h \neq g \end{cases}. \]
The characters of $G$ are elements of $\mathbb{C}^G$, so we can evaluate this inner product on pairs of characters.  The answer turns out to be very useful, but before we can begin the proof we require two quick lemmas:

\begin{lemma} \label{projection-lemma}
Let $V$ be a vector space with subspace $U \subset V$, and let $\pi \colon V \to V$ be a projection onto $U$.  Then 
\[ \text{Tr}(\pi) = \text{dim } U. \]
\end{lemma}
\begin{proof}
Recall that $V = U \oplus \text{Ker }(\pi)$ from Lemma \ref{maschke-lemma}. If we fix bases for $U$ and $\text{Ker }(\pi)$, which together give a basis for V, then $\pi$ is given by the block-diagonal matrix
\[   \begin{bmatrix}
\mathbf{1} & 0 \\
0 & \mathbf{0} \\
\end{bmatrix} \]
where $\text{dim U}$ is the size of the upper left block and $\text{dim Ker }(\pi)$ is the size of the bottom right block.  So $\text{Tr}(\pi) = \text{Tr}(\mathbf{1}_U) = \text{dim } U$.
\end{proof}

\begin{lemma}
Let $\rho \colon G \to GL(V)$ be any representation.  Consider the linear map 
\begin{align*}
\Psi \colon V &\to V \\
x &\mapsto \frac{1}{|G|} \sum_{g \in G} \rho(g)(x).
\end{align*}
Then $\Psi$ is a  projection from $V$ onto the invariant subspace $V^G$.
\end{lemma}
\begin{proof}
We need to check that $\Psi(x) \in V^G$ for all $x \in V$.  For any $h \in G$, 
\begin{align*}
\rho(h)(\Psi(x)) &= \frac{1}{|G|}  \sum_{g \in G} \rho(h)\rho(g)(x) \\
&= \frac{1}{|G|}\sum_{g \in G} \rho(h g) (x) \\
&= \frac{1}{|G|} \sum_{g \in G} \rho(g)(x) \quad (\text{by relabelling } g \mapsto h^{-1}g) \\
&= \Psi(x).
\end{align*}
Thus $\Psi$ is a linear map $V \to V^G$.  Finally we need to check that $\Psi \restriction_{V^G} = \text{Id}_{V^G}$.  Let $x \in V^G$.  Then
\begin{align*}
\Psi(x) &= \frac{1}{|G|} \sum_{g \in G} \rho(g)(x) \\
&= \frac{1}{|G|} \sum_{g \in G} (x) \\
&= \frac{|G|}{|G|} x= x.
\end{align*}
\end{proof}

\begin{thm}
Let $\rho_V \colon G \to GL(V)$ and $\rho_W \colon G \to GL(W)$ be representations of $G$, and let $\chi_V, \chi_W$ be their characters.  Then 
\[ \langle \chi_W | \chi_V \rangle = \text{dim Hom}_G (V,W). \]
\end{thm}
In particular, the inner product of two characters is always a non-negative integer.  (Whereas in general, the inner product of two arbitrary functions can be any complex number.)

\begin{proof}
We have seen in Proposition \ref{invariant-subrprn} that
 \[ \text{Hom}_G (V,W) \subset \text{Hom}(V,W) \] 
 as the invariant subrepresentation, and by the previous lemma we have a projection
\begin{align*}
\Psi \colon \text{Hom}(V,W) &\to \text{Hom}(V,W) \\
f &\mapsto \frac{1}{|G|} \sum_{g \in G} \rho_{\text{Hom}(V,W)} (g) (f).
\end{align*}
We claim that \[ \text{Tr} (\Psi) = \langle \chi_W | \chi_V \rangle. \]  Once this claim is established, then Lemma \ref{projection-lemma} will prove the theorem.  We proceed by calculating $\text{Tr} (\Psi)$.  Fix bases $\{ a_1, \ldots, a_n \}$ for $V$ and $\{ b_1, \ldots, b_m \}$ for $W$.  Then $\text{Hom}(V,W)$ has an associated basis 
\[ \{ f_{ji} | 1 \leq i \leq n, 1 \leq j \leq m\} \]
where
\[ f_{ji} (a_i) = \begin{cases} b_j &\text{if } i=j \\ 0 &\text{if } i \neq j.  \end{cases} \] 
We may calculate $\text{Tr}(\Psi)$ as follows:  For each $i,j$, compute the expression of $\Psi(f_{ji})$ in this basis, and take the coefficient of the basis element $f_{ji}$.  This is a diagonal entry in the matrix for $\Psi$. Summing these values over all $i$ and $j$ will gives us $\text{Tr}(\Psi)$.

Let $\widetilde{\rho_V}, \widetilde{\rho_W}$ be the matrix representations obtained by writing $\rho_V$ and $\rho_W$ in the given bases.  We know that 
\[ \text{Hom}(V,W) = V^* \otimes W \]
so if we write $\rho_{\text{Hom}(V,W)}$ in the basis $\{ f_{ji} \}$ then we get the tensor product of  $\widetilde{\rho_{V^*}}$ and $\widetilde{\rho_W}$.  Thus
\begin{align*}
\rho_{\text{Hom}(V,W)}(g)(f_{ji}) &= \rho_W (g) \circ f_{ji} \circ \rho_V (g^{-1}) \\
&= \sum_{\substack{k \in [1,n] \\  t \in [1,m]}} \widetilde{\rho_V} (g^{-1})_{ik} \widetilde{\rho_W}(g)_{tj} f_{kt}. \quad \text{Show another step?}
\end{align*}
Then 
\begin{align*}
\Psi (f_{ji}) &= \frac{1}{|G|} \sum_{g \in G} \rho_{\text{Hom}(V,W)}(g)(f) \\
&= \frac{1}{|G|} \sum_{g \in G} \sum_{\substack{k \in [1,n] \\  t \in [1,m]}} \widetilde{\rho_V} (g^{-1})_{ik} \widetilde{\rho_W}(g)_{tj} f_{kt}.
\end{align*}
The coefficient of $f_{ji}$ in this expression is
\[ \frac{1}{|G|} \sum_{g \in G}\widetilde{\rho_V} (g^{-1})_{ii} \widetilde{\rho_W}(g)_{jj}. \]
Therefore
\begin{align*}
\text{Tr} (\Psi) &= \sum_{\substack{k \in [1,n] \\  t \in [1,m]}}  \frac{1}{|G|} \sum_{g \in G}\widetilde{\rho_V} (g^{-1})_{ii} \widetilde{\rho_W}(g)_{jj} \\
&=  \frac{1}{|G|} \sum_{g \in G} \left( \sum_{i=1}^n \widetilde{\rho_V}(g^{-1})_{ii} \right) \left( \sum_{j=1}^m \widetilde{\rho_W} (g)_{jj} \right) \\
&= \frac{1}{|G|} \sum_{g \in G} \chi_V (g^{-1}) \chi_W (g) \\
&= \frac{1}{|G|} \sum_{g \in G} \chi_W (g) \overline{\chi_V}(g)  \quad \text{(by Proposition \ref{basic-props-of-char}.\ref{char-of-inverse})}\\
&= \langle \chi_W | \chi_V \rangle.
\end{align*}
\end{proof}

\begin{cor}\label{inner-product-of-irr-chars}
Let $\chi_1, \ldots, \chi_r$ be the irreducible characters of $G$.  Then
\[ \langle \chi_i | \chi_j \rangle = \begin{cases}  1 &\text{if } i = j \\ 0 &\text{if } i \neq j\end{cases} \]
\end{cor}
\begin{proof}
Let $\chi_i$ and $\chi_j$ be the characters of the irreducible representations $U_i, U_j$.  Then by Proposition \ref{schurs-lemma-homvw},

\[ \langle \chi_i | \chi_j \rangle = \text{dim Hom}_G (U_i, U_j) = \begin{cases}  1 &\text{if }U_i, U_j \text{ are isomorphic} \\  0 &\text{if }U_i, U_j \text{ are not isomorphic}. \end{cases} \]
\end{proof}

\begin{cor}
Let $\chi$ be any character of $G$.    Then $\chi$ is irreducible if and only if \[ \langle \chi | \chi \rangle = 1\]
\end{cor}
\begin{proof}
Write $\chi$ as a linear combination of irreducible characters \[ \chi = m_1 \chi_1 + \ldots + m_k \chi_k \] where each $m_i$ is a non-negative integer.  Then by Lemma \ref{inner-product-of-irr-chars}, 
\begin{align*}
\langle \chi | \chi \rangle &= \sum_{i,j \in [1, k]} m_i m_j \langle \chi_i | \chi_j \rangle \\
&= m_1^2 + \ldots + m_k^2.
\end{align*}
So $\langle \chi | \chi \rangle = 1$ if and only if exactly one of the $m_i = 1$ and the rest are $0$.
\end{proof}

\begin{cor}
Let $\rho_V \colon G \to GL(V)$ and $\rho_W \colon G \to GL(W)$ be representations of $G$.  Then $V$ and $W$ are isomorphic if and only if $\chi_V = \chi_W$.
\end{cor}
\begin{proof}
We have already seen that isomorphic representations have the same character by Proposition \label{iso-reprns-same-char}.  On the other hand, suppose $\chi_V = \chi_W$.  Let $U_1, \ldots, U_r$ be the irreducible representations of $G$, and let $\chi_1, \ldots, \chi_r$ be their characters.  We can write
\[ V = U_1^{m_1} \oplus \ldots \oplus U_r^{m_r} \]
for some non-negative integers $m_1, \ldots, m_r$, and 
\[ W = U_1^{l_1} \oplus \ldots \oplus U_r^{l_r} \]
for some non-negative integers $l_1, \ldots, l_r$.  So
\[ \chi_V = m_1 \chi_1 + \ldots + m_r \chi_r \]
and 
\[ \chi_W = l_1 \chi_1 + \ldots + l_r \chi_r .\]
Thus we have 
\[ m_i = \langle \chi_V | \chi_i \rangle = \langle \chi_W | \chi_i \rangle = l_i \]
for all $i \in \{1, \ldots, r \}$ since $\chi_V = \chi_W$.  This proves $V$ and $W$ are isomorphic.
\end{proof}

\begin{defn}
A \textbf{class function} on $G$ is a function on $G$ whose values are invariant by conjugation of elements in $G$.  The value of a class function at an element $g \in G$ depends only on the conjugacy class of $g$.  We may therefore view class functions as functions on the set of conjugacy classes of $G$.
\end{defn}
\begin{note}
The character $\chi_V$ of a representation $V$ of $G$ is a class function on $G$.
\end{note}